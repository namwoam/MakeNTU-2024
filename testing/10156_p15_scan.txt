C.2. Joint prediction and planning PRECOG [81] proposes a Iecurrent model that condi- tions forecasting On the goal position Of the ego vehicle_ while PjP [86] generates agents motion considering com- plete presumed planning trajectories. However, producing a rough future trajectory is still challenging in the real world, toward which [62] presents deep structured model to de- rive both prediction and planning from the same setof leamn- able costs. [39,40] couple the prediction model with classic optimization methods Meanwhile; some motion forecast- ing methods implicitly include the planning task by produc- jg their future trajectories simultaneously [12,45,70]. Sim- ilarly, we encode possible behaviors Of the ego vehicle i the scene-centric motion forecasting module, but the inter- pretable occupancy map is utilized to further optimize the plan to stay safe。 C.3. End-to-end motion planning End-to-end motion planning has been an active research domain since Pomerleau [77] uses single neural network that directly predicts control signals。 Subsequent studies make great advances especially i closed-loop simulation with deeper networks [4], multi-modal inputs [2,21,78], multi-task learning [20,97], reinforcement learning [13,14, 46,59,89] and distillation from certain Privilege knowl- edge [16,103,106]. However; for such methods of directly generating control outputs from SenSOr data。 the transfer from the synthetic environment to realistic application IC- mains problem considering their robustness and safety assurance [22,38]. Thus researchers aim at explicitly de- signing the intermediate representations of the network to Prompt safety, where predicting how the scene evolves at- tracts broad interest. Some works [19,34,83] jointly decode planning and BEV semantic predictions to enhance inter- pretability, while PLOP [5] adopts a polynomial formula- tion to provide smooth planning results for both ego vehi- cle and neighbors. Cui et al. [24] introduce contingency planner with diverse sets Of future predictions and LAV [15] trains the Planner With al1 vehicles trajectories to provide richer training data. NMP [101] and its variant [94] estimate a COSt volume to select the Plan with minimal cost besides deterministic future perception. Though they risk producing inconsistent results between tWo modules, the cost map de- Sign is intuitive tO Iecover the final Plan in complex scenar- ios. Inspired by [101], most recent works [11,37,38,82,102] Propose models that construct costs with both learned occU- pancy prediction and hand-crafted penalties. However, their performances heavily rely on the tailored cost based on hu- Ianl experience and the distribution from where trajectories are sampled [47]. Contrary to these approaches, we lever- age the ego-motion information without sophisticated cost design and present the first attempt that incorporates the tracking module along with two genres Of prediction rep- resentations simultaneously in an end-to-end model。 D. Notations We provide a lookup table Of notations and their shapes mentioned in this paper in Table 11 for reference。 卫. Implementation Details 卫1. Detection and Tracking We iherit most of the detection designs from BEV- Former [55] Which takes BEV encoder to transform 迎- age features into BEV feature B and adopts a Deformable DETR head [109] to perform detection on 召 To further conduct end-to-end tracking without heavy post association。 we introduce another grouP Of queries named track queries as i MOTR [100] which continuously tracks previously Ob- served instances according to its assigned track I。 We 讧- troduce the tracking process in detail below。 Training stage: At the beginning (ie. first frame) Of each training sequence, all queries are considered detection queries and predict all newborn objects, which is actually the SaIC a8 BEVFormer。 Detection queries are matched to the ground truth by the Hungarian algorithm [8]. They Will be stored and updated via the query interaction module (QIM) for the next timestamnp serving as track queries fol- lowing MOTR [100]. 皿 the next timestammp; track queries Will be directly matched with part Of ground-truth ob- jects according to the corresponding track ID, and detection queries will be matched With the remaining ground-truth objects (newborn objects). To stabilize training, we adopt the 3D IoU metric to filter the matched queries. Only those predictions having the 3D IOU with ground-truth boxes larger than a certain threshold (0.5 in practice) will be stored and updated。 Inference stage: Different from the training stage, each frame of sequence is sent to the network sequentially。 meaning that track queries could exist for longer horizon than the training time。 Another difference emerging 讥 the inference stage is about query updating, that we use classi- fication scores to filter the queries (0.4 for detection queries and 0.35 for track queries in practice) instead Of the 3D IoU metric since the ground truth is not available_ Besides, to avoid the interruption of tracklets caused by short-time oc- Clusion, We USE lfecycle mechanism for the tracklets i the inference stage。 Specifically; for each track query。 i will be considered to disappear completely and be removed only When its corresponding classification score is smaller than 0.35 for 3 continuous period (2s in practice). 卫.2. Online Mapping Following [56], we decompose the map query Sel ito thing queries and stuff queries。 The thing queries model instance-wise maP elements (i.e., lanes, boundaries。 and 15